{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Vice Presidential and Presidential Debate Analysis\n",
    "* Debates are a tool for the candidates to appeal to an audience deciding who to vote for in the election. \n",
    "    * Viewers of these debates might already have a candidate in mind, but the audience isn't directed towards only one side, like the conventions. \n",
    "* This analysis will include a classifier, which will try to predict if a spoken line is republican or democratic.\n",
    "    * Goal: find key words used by each candidate to further their arguments. Also, find accuracy of the classifier for my hypothesis. \n",
    "* I will also be making a model based off of token length to see if speaking a lot is a persuasion choice made by the candidates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns        # seaborn graphical package\n",
    "sns.set_style('darkgrid')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "R    193\n",
       "D    131\n",
       "Name: Aff, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "presdebate = pd.read_csv(\"/Users/emmatarcson/Documents/data_science/RhetoricalFactor-analysis/data/only_D_and_R/welkerPRESdebate.csv\")\n",
    "presdebate = presdebate[['Aff','transcript']]\n",
    "presdebate.Aff.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "trans_toks = [nltk.word_tokenize(re.sub(r'[^\\w+ ]', '', t.lower())) for t in presdebate['transcript']]\n",
    "trans_tok_lens = [len(t) for t in trans_toks]\n",
    "sents = [len(nltk.sent_tokenize(t)) for t in presdebate['transcript']]\n",
    "presdebate['Token_Len'] = trans_tok_lens\n",
    "presdebate['SentAmt'] = sents\n",
    "presdebate['AVGSENTLEN'] = presdebate.Token_Len/presdebate.SentAmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Aff</th>\n",
       "      <th>transcript</th>\n",
       "      <th>Token_Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R</td>\n",
       "      <td>How are you doing? How are you?</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R</td>\n",
       "      <td>So as you know, 2.2 million people modeled out...</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R</td>\n",
       "      <td>There was a very big spike in Texas. It’s now ...</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R</td>\n",
       "      <td>I can tell you from personal experience, I was...</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D</td>\n",
       "      <td>220,000 Americans dead. You hear nothing else ...</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>R</td>\n",
       "      <td>Before the plague came in, just before, I was ...</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>R</td>\n",
       "      <td>Success is going to bring us together. We are ...</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>D</td>\n",
       "      <td>I will say, I’m an American President. I repre...</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>D</td>\n",
       "      <td>We can grow this economy, we can deal with the...</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>D</td>\n",
       "      <td>Thank you.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>324 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Aff                                         transcript  Token_Len\n",
       "0     R                    How are you doing? How are you?          7\n",
       "1     R  So as you know, 2.2 million people modeled out...        101\n",
       "2     R  There was a very big spike in Texas. It’s now ...         73\n",
       "3     R  I can tell you from personal experience, I was...        191\n",
       "4     D  220,000 Americans dead. You hear nothing else ...        102\n",
       "..   ..                                                ...        ...\n",
       "319   R  Before the plague came in, just before, I was ...         76\n",
       "320   R  Success is going to bring us together. We are ...         71\n",
       "321   D  I will say, I’m an American President. I repre...         71\n",
       "322   D  We can grow this economy, we can deal with the...        103\n",
       "323   D                                         Thank you.          2\n",
       "\n",
       "[324 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "presdebate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5846153846153846"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "X = presdebate[['Token_Len', 'AVGSENTLEN', 'SentAmt']]\n",
    "y = presdebate['Aff']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.6, random_state=0)\n",
    "\n",
    "\n",
    "lr_model = LogisticRegression()   # default setting\n",
    "lr_model.fit(X_train, y_train)\n",
    "y_pred = lr_model.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100000.0, kernel='linear')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(presdebate['transcript'], presdebate['Aff'], random_state=0,\n",
    "                                  train_size=0.6)\n",
    "vectorizer = TfidfVectorizer(min_df=1, max_features=4000, tokenizer=nltk.word_tokenize)\n",
    "\n",
    "X_text_train = vectorizer.fit_transform(X_train)\n",
    "X_text_test = vectorizer.transform(X_test)\n",
    "\n",
    "from sklearn.svm import SVC \n",
    "svcmodel = SVC(kernel='linear', C=1E5)  \n",
    "svcmodel.fit(X_text_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "295    R\n",
      "65     R\n",
      "15     D\n",
      "274    D\n",
      "140    D\n",
      "153    D\n",
      "101    D\n",
      "234    R\n",
      "63     D\n",
      "159    R\n",
      "184    D\n",
      "181    R\n",
      "97     D\n",
      "219    D\n",
      "215    D\n",
      "64     R\n",
      "26     R\n",
      "256    R\n",
      "92     R\n",
      "108    R\n",
      "Name: Aff, dtype: object\n",
      "['R' 'R' 'D' 'R' 'D' 'D' 'D' 'R' 'R' 'R' 'D' 'R' 'D' 'D' 'R' 'R' 'R' 'R'\n",
      " 'D' 'R']\n"
     ]
    }
   ],
   "source": [
    "pred = svcmodel.predict(X_text_test)\n",
    "print(y_test[:20])\n",
    "print(pred[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6615384615384615"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, pred) #wow, not that good with a debate. these are just with sentences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letssee = [x for x in pred if x == 'R']\n",
    "len(letssee) #how many times it predicted R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emmatarcson/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass labels=['D', 'R'] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "labels = ['D','R']\n",
    "mat = confusion_matrix(y_test, pred, labels)\n",
    "sns.heatmap(mat, square=True, annot=True, fmt='d', cmap=\"Reds\",\n",
    "           xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel('predicted label')\n",
    "plt.ylabel('true label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like it guessed 'R' wrongly a lot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "R    131\n",
       "D    131\n",
       "Name: Aff, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's do it with cleaner data\n",
    "\n",
    "just_R = presdebate[presdebate.Aff == 'R']\n",
    "just_R = just_R[:131]\n",
    "just_D = presdebate[presdebate.Aff == 'D']\n",
    "presdebate2 = pd.concat([just_R, just_D])\n",
    "presdebate2.Aff.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6857142857142857"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(presdebate2['transcript'], presdebate2['Aff'], random_state=0,\n",
    "                                  train_size=0.6)\n",
    "vectorizer = TfidfVectorizer(min_df=1, max_features=4000, tokenizer=nltk.word_tokenize)\n",
    "\n",
    "X_text_train = vectorizer.fit_transform(X_train)\n",
    "X_text_test = vectorizer.transform(X_test)\n",
    "\n",
    "from sklearn.svm import SVC \n",
    "svcmodel = SVC(kernel='linear', C=1E5)  \n",
    "svcmodel.fit(X_text_train, y_train)\n",
    "pred = svcmodel.predict(X_text_test)\n",
    "accuracy_score(y_test, pred) #worked a little better but nothing satisying. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the coefficent flattens with binary classes, so I'm still currently looking for a way to find the most informative\n",
    "# features :/\n",
    "\n",
    "# otherwise, I will need to use the csv file with the all three speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "R       193\n",
       "None    188\n",
       "D       131\n",
       "Name: Aff, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allpresdebate = pd.read_csv(\"/Users/emmatarcson/Documents/data_science/RhetoricalFactor-analysis/data/all_speakers/presdebatewelker.csv\")\n",
    "allpresdebate = allpresdebate[['Aff','transcript']]\n",
    "allpresdebate.Aff.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evening them out, otherwise it was barely guessing 'D'\n",
    "just_R = allpresdebate[allpresdebate.Aff == 'R']\n",
    "just_R = just_R[:131]\n",
    "just_none = allpresdebate[allpresdebate.Aff == 'None']\n",
    "just_none = just_none[:131]\n",
    "just_D = allpresdebate[allpresdebate.Aff == 'D']\n",
    "allpresdebate2 = pd.concat([just_R, just_D, just_none])\n",
    "allpresdebate2.Aff.value_counts()\n",
    "shuf_data = allpresdebate2.sample(frac=1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7784810126582279"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(shuf_data['transcript'], shuf_data['Aff'], random_state=0,\n",
    "                                  train_size=0.6)\n",
    "nbmodel = MultinomialNB()\n",
    "vectorizer = TfidfVectorizer(max_df=0.5, min_df=2,max_features=1500, stop_words='english') #using this to find vocab\n",
    "X_text_train = vectorizer.fit_transform(X_train)\n",
    "X_text_test = vectorizer.transform(X_test)\n",
    "\n",
    "\n",
    "nbmodel.fit(X_text_train, y_train)\n",
    "pred = nbmodel.predict(X_text_test)\n",
    "accuracy_score(y_test, pred) \n",
    "#the accuracy actually got better... maybe this is because features become more polarized when there is neutral weight?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.55251847, -5.75933542, -6.57989899, ..., -6.47886584,\n",
       "        -6.44956437, -6.12571365],\n",
       "       [-5.91108231, -6.18081174, -6.17628992, ..., -6.54489505,\n",
       "        -6.27528041, -6.36434925],\n",
       "       [-5.41725611, -6.27436623, -6.3043343 , ..., -5.92007281,\n",
       "        -6.23543389, -6.5677607 ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbmodel.coef_ #nice! we actually have separated coefficent lists this time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letssee = [x for x in pred if x == 'D']\n",
    "len(letssee) #how many times it predicted R, this just makes sure the confusion matrix has the right labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emmatarcson/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass labels=['D', 'R', 'None'] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# it never predicted as m\n",
    "from sklearn.metrics import confusion_matrix\n",
    "labels = ['D','R','None']\n",
    "mat = confusion_matrix(y_test, pred, labels)\n",
    "sns.heatmap(mat, square=True, annot=True, fmt='d', cmap=\"Reds\",\n",
    "           xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel('predicted label')\n",
    "plt.ylabel('true label')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D: lot, years, clear, plan, guy, healthcare, industry, 000, united, crosstalk, money, american, know, oil, transition, come, republican, didn, things, wrong, deal, look, don, stop, states, president, 00, talking, fracking, fact, make, people, did, sure, china, way, respond, said, true, going\n",
      "None: hill, capitol, haven, american, ve, section, tell, need, new, ask, immigration, questions, reaction, 10, uninterrupted, 30, korea, recently, gentlemen, north, minutes, families, mr, follow, respond, want, said, seconds, right, talk, question, going, quickly, okay, response, biden, vice, let, trump, president\n",
      "R: politician, soon, kristen, places, big, 28, country, built, different, gave, million, doesn, did, cages, ago, typical, respond, know, got, crosstalk, ve, didn, years, china, thing, said, work, like, going, just, people, 00, doing, say, joe, money, come, think, excuse, don\n"
     ]
    }
   ],
   "source": [
    "def print_top(vectorizer, clf, class_labels, n):\n",
    "    \"\"\"Prints features with the highest coefficient values, per class\"\"\"\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    for i, class_label in enumerate(class_labels):\n",
    "        top = np.argsort(clf.coef_[i])[0-n:]\n",
    "        print(\"%s: %s\" % (class_label,\n",
    "              \", \".join(feature_names[j].replace(' ', '-') for j in top)))\n",
    "    \n",
    "\n",
    "print_top(vectorizer, nbmodel, nbmodel.classes_, 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* joe, joe, joe.. fracking...\n",
    "* D: 'fact'? -> people at home watching the debate and hear 'fact'... \n",
    "* it does seem like they are using some rhetorically weighted words like 'healthcare', 'united', 'immigration'\n",
    "* with debates, I expect like super heavy words that pull people's attention and whatnot\n",
    "* honestly, looking at this, I feel like I could predict correctly which is which\n",
    "    * that being said, though, the classifier was a little worse that the speeches, which says to me that debates use speech that will attract both sides? Or maybe since they both had to answer questions about specific topics, which makes it interesting that there was still a bit of weight tied to certain topic words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'So as you know, 2.2 million people modeled out, were expected to die. We closed up the greatest economy in the world in order to fight this horrible disease that came from China. It’s a worldwide pandemic. It’s all over the world. You see the spikes in Europe and many other places right now. If you notice, the mortality rate is down 85%. The excess mortality rate is way down and much lower than almost any other country. And we’re fighting it and we’re fighting it hard. There is a spike. There was a spike in Florida and it’s now gone.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I'm gonna add more features\n",
    "\n",
    "presdebate.transcript[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "trans_toks = [nltk.word_tokenize(re.sub(r'[^\\w+ ]', '', t.lower())) for t in presdebate['transcript']]\n",
    "trans_tok_lens = [len(t) for t in trans_toks]\n",
    "type_len = [len(set(t)) for t in trans_toks]\n",
    "TTR = [len(set(t))/len(t) for t in trans_toks]\n",
    "\n",
    "presdebate['Toks'] = trans_toks\n",
    "presdebate['Token_count'] = trans_tok_lens\n",
    "presdebate['Type_count'] = type_len\n",
    "presdebate['TTR'] = TTR # might have to get rid of words that only have a couple words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Aff</th>\n",
       "      <th>transcript</th>\n",
       "      <th>Toks</th>\n",
       "      <th>Token_count</th>\n",
       "      <th>Type_count</th>\n",
       "      <th>TTR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R</td>\n",
       "      <td>How are you doing? How are you?</td>\n",
       "      <td>[how, are, you, doing, how, are, you]</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R</td>\n",
       "      <td>So as you know, 2.2 million people modeled out...</td>\n",
       "      <td>[so, as, you, know, 22, million, people, model...</td>\n",
       "      <td>101</td>\n",
       "      <td>68</td>\n",
       "      <td>0.673267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R</td>\n",
       "      <td>There was a very big spike in Texas. It’s now ...</td>\n",
       "      <td>[there, was, a, very, big, spike, in, texas, i...</td>\n",
       "      <td>73</td>\n",
       "      <td>42</td>\n",
       "      <td>0.575342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R</td>\n",
       "      <td>I can tell you from personal experience, I was...</td>\n",
       "      <td>[i, can, tell, you, from, personal, experience...</td>\n",
       "      <td>191</td>\n",
       "      <td>106</td>\n",
       "      <td>0.554974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D</td>\n",
       "      <td>220,000 Americans dead. You hear nothing else ...</td>\n",
       "      <td>[220000, americans, dead, you, hear, nothing, ...</td>\n",
       "      <td>102</td>\n",
       "      <td>70</td>\n",
       "      <td>0.686275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>R</td>\n",
       "      <td>Before the plague came in, just before, I was ...</td>\n",
       "      <td>[before, the, plague, came, in, just, before, ...</td>\n",
       "      <td>76</td>\n",
       "      <td>53</td>\n",
       "      <td>0.697368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>R</td>\n",
       "      <td>Success is going to bring us together. We are ...</td>\n",
       "      <td>[success, is, going, to, bring, us, together, ...</td>\n",
       "      <td>71</td>\n",
       "      <td>53</td>\n",
       "      <td>0.746479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>D</td>\n",
       "      <td>I will say, I’m an American President. I repre...</td>\n",
       "      <td>[i, will, say, im, an, american, president, i,...</td>\n",
       "      <td>71</td>\n",
       "      <td>42</td>\n",
       "      <td>0.591549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>D</td>\n",
       "      <td>We can grow this economy, we can deal with the...</td>\n",
       "      <td>[we, can, grow, this, economy, we, can, deal, ...</td>\n",
       "      <td>103</td>\n",
       "      <td>70</td>\n",
       "      <td>0.679612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>D</td>\n",
       "      <td>Thank you.</td>\n",
       "      <td>[thank, you]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>324 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Aff                                         transcript  \\\n",
       "0     R                    How are you doing? How are you?   \n",
       "1     R  So as you know, 2.2 million people modeled out...   \n",
       "2     R  There was a very big spike in Texas. It’s now ...   \n",
       "3     R  I can tell you from personal experience, I was...   \n",
       "4     D  220,000 Americans dead. You hear nothing else ...   \n",
       "..   ..                                                ...   \n",
       "319   R  Before the plague came in, just before, I was ...   \n",
       "320   R  Success is going to bring us together. We are ...   \n",
       "321   D  I will say, I’m an American President. I repre...   \n",
       "322   D  We can grow this economy, we can deal with the...   \n",
       "323   D                                         Thank you.   \n",
       "\n",
       "                                                  Toks  Token_count  \\\n",
       "0                [how, are, you, doing, how, are, you]            7   \n",
       "1    [so, as, you, know, 22, million, people, model...          101   \n",
       "2    [there, was, a, very, big, spike, in, texas, i...           73   \n",
       "3    [i, can, tell, you, from, personal, experience...          191   \n",
       "4    [220000, americans, dead, you, hear, nothing, ...          102   \n",
       "..                                                 ...          ...   \n",
       "319  [before, the, plague, came, in, just, before, ...           76   \n",
       "320  [success, is, going, to, bring, us, together, ...           71   \n",
       "321  [i, will, say, im, an, american, president, i,...           71   \n",
       "322  [we, can, grow, this, economy, we, can, deal, ...          103   \n",
       "323                                       [thank, you]            2   \n",
       "\n",
       "     Type_count       TTR  \n",
       "0             4  0.571429  \n",
       "1            68  0.673267  \n",
       "2            42  0.575342  \n",
       "3           106  0.554974  \n",
       "4            70  0.686275  \n",
       "..          ...       ...  \n",
       "319          53  0.697368  \n",
       "320          53  0.746479  \n",
       "321          42  0.591549  \n",
       "322          70  0.679612  \n",
       "323           2  1.000000  \n",
       "\n",
       "[324 rows x 6 columns]"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "presdebate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "R    113\n",
       "D     94\n",
       "Name: Aff, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vpdebate = pd.read_csv(\"/Users/emmatarcson/Documents/data_science/RhetoricalFactor-analysis/data/only_D_and_R/pageVPdebate.csv\")\n",
    "vpdebate = vpdebate[['Aff','transcript']]\n",
    "vpdebate.Aff.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7831325301204819"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(vpdebate['transcript'], vpdebate['Aff'], random_state=0,\n",
    "                                  train_size=0.6)\n",
    "vectorizer = TfidfVectorizer(min_df=1, max_features=4000, tokenizer=nltk.word_tokenize)\n",
    "\n",
    "X_text_train = vectorizer.fit_transform(X_train)\n",
    "X_text_test = vectorizer.transform(X_test)\n",
    "\n",
    "from sklearn.svm import SVC \n",
    "svcmodel = SVC(kernel='linear', C=1E5)  \n",
    "svcmodel.fit(X_text_train, y_train)\n",
    "pred = svcmodel.predict(X_text_test)\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "None    120\n",
       "R       113\n",
       "D        94\n",
       "Name: Aff, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allvpdebate = pd.read_csv(\"/Users/emmatarcson/Documents/data_science/RhetoricalFactor-analysis/data/all_speakers/pagedebate2020.csv\")\n",
    "allvpdebate = allvpdebate[['Aff','transcript']]\n",
    "allvpdebate.Aff.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "just_R = allvpdebate[allvpdebate.Aff == 'R']\n",
    "just_R = just_R[:94]\n",
    "just_none = allvpdebate[allvpdebate.Aff == 'None']\n",
    "just_none = just_none[:94]\n",
    "just_D = allvpdebate[allvpdebate.Aff == 'D']\n",
    "allvpdebate2 = pd.concat([just_R, just_D, just_none])\n",
    "allvpdebate2.Aff.value_counts()\n",
    "shuf_data = allvpdebate2.sample(frac=1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7345132743362832"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(shuf_data['transcript'], shuf_data['Aff'], random_state=0,\n",
    "                                  train_size=0.6)\n",
    "nbmodel = MultinomialNB()\n",
    "vectorizer = TfidfVectorizer(max_df=0.5, min_df=2,max_features=1500, stop_words='english') #using this to find vocab\n",
    "X_text_train = vectorizer.fit_transform(X_train)\n",
    "X_text_test = vectorizer.transform(X_test)\n",
    "\n",
    "\n",
    "nbmodel.fit(X_text_train, y_train)\n",
    "pred = nbmodel.predict(X_text_test)\n",
    "accuracy_score(y_test, pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D: future, record, calm, justice, respond, country, criminal, united, time, great, doesn, need, 000, states, packing, mr, vice, administration, based, like, stage, means, talk, fact, leadership, jobs, american, trump, president, donald, issue, know, america, said, thank, biden, speaking, people, let, joe\n",
      "None: tonight, right, good, presidential, question, make, voters, time, segue, court, covid, trump, information, course, china, death, think, need, uninterrupted, trying, important, ve, administration, talk, 15, seconds, americans, minutes, issue, topic, respond, yes, chance, want, harris, senator, president, pence, vice, thank\n",
      "R: china, jobs, pandemic, economy, really, reality, regard, year, just, like, question, know, answer, coronavirus, states, continue, united, believe, said, court, look, supreme, america, did, green, million, joe, deal, biden, years, new, donald, senator, going, people, ve, trump, president, susan, american\n"
     ]
    }
   ],
   "source": [
    "def print_top(vectorizer, clf, class_labels, n):\n",
    "    \"\"\"Prints features with the highest coefficient values, per class\"\"\"\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    for i, class_label in enumerate(class_labels):\n",
    "        top = np.argsort(clf.coef_[i])[0-n:]\n",
    "        print(\"%s: %s\" % (class_label,\n",
    "              \", \".join(feature_names[j].replace(' ', '-') for j in top)))\n",
    "    \n",
    "\n",
    "print_top(vectorizer, nbmodel, nbmodel.classes_, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "trans_toks = [nltk.word_tokenize(re.sub(r'[^\\w+ ]', '', t.lower())) for t in vpdebate['transcript']]\n",
    "trans_tok_lens = [len(t) for t in trans_toks]\n",
    "type_len = [len(set(t)) for t in trans_toks]\n",
    "TTR = [len(set(t))/len(t) for t in trans_toks]\n",
    "\n",
    "vpdebate['Toks'] = trans_toks\n",
    "vpdebate['Token_count'] = trans_tok_lens\n",
    "vpdebate['Type_count'] = type_len\n",
    "vpdebate['TTR'] = TTR # might have to get rid of words that only have a couple words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Aff</th>\n",
       "      <th>transcript</th>\n",
       "      <th>Toks</th>\n",
       "      <th>Token_count</th>\n",
       "      <th>Type_count</th>\n",
       "      <th>TTR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D</td>\n",
       "      <td>Thank you, Susan. Well, the American people ha...</td>\n",
       "      <td>[thank, you, susan, well, the, american, peopl...</td>\n",
       "      <td>146</td>\n",
       "      <td>87</td>\n",
       "      <td>0.595890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D</td>\n",
       "      <td>Can you imagine if you knew on January 28th, a...</td>\n",
       "      <td>[can, you, imagine, if, you, knew, on, january...</td>\n",
       "      <td>177</td>\n",
       "      <td>87</td>\n",
       "      <td>0.491525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D</td>\n",
       "      <td>… right to reelection based on this.</td>\n",
       "      <td>[right, to, reelection, based, on, this]</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R</td>\n",
       "      <td>Susan, thank you. And I want to thank the Comm...</td>\n",
       "      <td>[susan, thank, you, and, i, want, to, thank, t...</td>\n",
       "      <td>163</td>\n",
       "      <td>108</td>\n",
       "      <td>0.662577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R</td>\n",
       "      <td>And I believe it saved hundreds of thousands o...</td>\n",
       "      <td>[and, i, believe, it, saved, hundreds, of, tho...</td>\n",
       "      <td>198</td>\n",
       "      <td>118</td>\n",
       "      <td>0.595960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>R</td>\n",
       "      <td>I look at the relationship between Justice Rut...</td>\n",
       "      <td>[i, look, at, the, relationship, between, just...</td>\n",
       "      <td>185</td>\n",
       "      <td>110</td>\n",
       "      <td>0.594595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>D</td>\n",
       "      <td>First of all, I love hearing from our young le...</td>\n",
       "      <td>[first, of, all, i, love, hearing, from, our, ...</td>\n",
       "      <td>57</td>\n",
       "      <td>37</td>\n",
       "      <td>0.649123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>D</td>\n",
       "      <td>And brings me to Joe, Joe Biden. One of the re...</td>\n",
       "      <td>[and, brings, me, to, joe, joe, biden, one, of...</td>\n",
       "      <td>73</td>\n",
       "      <td>50</td>\n",
       "      <td>0.684932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>D</td>\n",
       "      <td>Joe has a longstanding reputation of working a...</td>\n",
       "      <td>[joe, has, a, longstanding, reputation, of, wo...</td>\n",
       "      <td>61</td>\n",
       "      <td>42</td>\n",
       "      <td>0.688525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>D</td>\n",
       "      <td>Brecklin, when you think about the future, I d...</td>\n",
       "      <td>[brecklin, when, you, think, about, the, futur...</td>\n",
       "      <td>69</td>\n",
       "      <td>46</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>207 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Aff                                         transcript  \\\n",
       "0     D  Thank you, Susan. Well, the American people ha...   \n",
       "1     D  Can you imagine if you knew on January 28th, a...   \n",
       "2     D               … right to reelection based on this.   \n",
       "3     R  Susan, thank you. And I want to thank the Comm...   \n",
       "4     R  And I believe it saved hundreds of thousands o...   \n",
       "..   ..                                                ...   \n",
       "202   R  I look at the relationship between Justice Rut...   \n",
       "203   D  First of all, I love hearing from our young le...   \n",
       "204   D  And brings me to Joe, Joe Biden. One of the re...   \n",
       "205   D  Joe has a longstanding reputation of working a...   \n",
       "206   D  Brecklin, when you think about the future, I d...   \n",
       "\n",
       "                                                  Toks  Token_count  \\\n",
       "0    [thank, you, susan, well, the, american, peopl...          146   \n",
       "1    [can, you, imagine, if, you, knew, on, january...          177   \n",
       "2             [right, to, reelection, based, on, this]            6   \n",
       "3    [susan, thank, you, and, i, want, to, thank, t...          163   \n",
       "4    [and, i, believe, it, saved, hundreds, of, tho...          198   \n",
       "..                                                 ...          ...   \n",
       "202  [i, look, at, the, relationship, between, just...          185   \n",
       "203  [first, of, all, i, love, hearing, from, our, ...           57   \n",
       "204  [and, brings, me, to, joe, joe, biden, one, of...           73   \n",
       "205  [joe, has, a, longstanding, reputation, of, wo...           61   \n",
       "206  [brecklin, when, you, think, about, the, futur...           69   \n",
       "\n",
       "     Type_count       TTR  \n",
       "0            87  0.595890  \n",
       "1            87  0.491525  \n",
       "2             6  1.000000  \n",
       "3           108  0.662577  \n",
       "4           118  0.595960  \n",
       "..          ...       ...  \n",
       "202         110  0.594595  \n",
       "203          37  0.649123  \n",
       "204          50  0.684932  \n",
       "205          42  0.688525  \n",
       "206          46  0.666667  \n",
       "\n",
       "[207 rows x 6 columns]"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vpdebate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 531 entries, 0 to 323\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Aff         531 non-null    object\n",
      " 1   transcript  531 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 12.4+ KB\n"
     ]
    }
   ],
   "source": [
    "alldebates = pd.concat([vpdebate, presdebate])\n",
    "alldebates.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, kernel='linear')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(alldebates['transcript'], alldebates['Aff'], random_state=0,\n",
    "                                  train_size=0.6)\n",
    "vectorizer = TfidfVectorizer(max_df = .5, min_df=1, max_features=2000, tokenizer = nltk.word_tokenize)\n",
    "\n",
    "X_text_train = vectorizer.fit_transform(X_train)\n",
    "X_text_test = vectorizer.transform(X_test)\n",
    "\n",
    "from sklearn.svm import SVC \n",
    "svcmodel = SVC(kernel='linear', C=1)  \n",
    "svcmodel.fit(X_text_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7699530516431925"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = svcmodel.predict(X_text_test)\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emmatarcson/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass labels=['D', 'R'] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATgAAAEECAYAAAC8xyi8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAb1UlEQVR4nO3deXxU9dn38c+ZCQkkrAGsShASFkW9cQFlUeljhQJVbyViQnITBOvCojVshiUQFSHlQRYJRZCHpYQtQaN3W0tVkJvcoqTYqiCCyKLsa1LDJJBMMuf5gxpJIc3MZJKZOXzfvs7LzJnJORcJXK/rd36/cy7DNE0TERELsvk7ABGR2qIEJyKWpQQnIpalBCcilqUEJyKWFeLvAP5VWepgf4cgHghJTvd3COKNFq1r9O3DjcZuf3aRWVijc9WEKjgRsayAq+BEJPAFS2WkBCciHgsxDH+H4BYlOBHxmC048psSnIh4TkNUEbEsm4aoImJVquBExLJ0DU5ELMuuIaqIWFWwDFGDJU4RCSA2w/3NHV9++SVJSUkAfP/99yQkJJCYmEhaWhoulwuA7OxsYmNjiYuLY/Pmze7F6dWfTkSuajYPtuosWbKE1NRUSkpKAEhPTyc5OZk1a9ZgmiabNm3i9OnTZGZmsm7dOpYuXcqcOXMoLS11K04REY/YDMPtLSsri9jY2IotKyur0rFuuOEGMjIyKl7v2rWLu+++G4BevXrxySefsGPHDu644w5CQ0Np1KgRN9xwA3v27Kk2Tl2DExGPhXgwxxAfH098fHyV7/ft25cjR45UvDZNE+OfkxgRERGcO3cOh8NBo0aNKj4TERGBw+GoPk73wxQRuag2h342209HLyoqonHjxjRs2JCioqJK+y9NeFUeq1YiFBFLs2G4vXnq5ptvJi8vD4Dc3Fy6du1K586d+dvf/kZJSQnnzp1j//79dOzYsdpjqYITEY/V5kLflJQUpkyZwpw5c4iJiaFv377Y7XaSkpJITEzENE1Gjx5NWFhYtccyAq0vqp7oG1z0RN8gVcMn+s4Nb+72Z0cXn63RuWpCFZyIeEy3aomIZemBlyJiWcEyO6kEJyIe0xBVRCzLm+Uf/qAEJyIeUwUnIpZlV4ITEavSEFVELEtDVBGxLC0TERHLCpICTglORDynvqgiYlkaooqIZQVH/aYEJyJeMDREFRGrCo70pgQnIl7QNTgRsawgGaEqwYmI53x5q1ZpaSkTJ07k8OHDNGzYkKlTp2IYBhMmTMAwDDp06EBaWlqlblvuUoITEY/5soDLzs4mPDyc7OxsDhw4wLRp06hXrx7Jycl069aNqVOnsmnTJvr06ePxsYNlKC0iAcRmuL9VZ9++ffTq1QuAmJgY9u/ff8Xu9l7F6dV3ichVzfDgv6ysLGJjYyu2rKysSsfq1KkTmzdvxjRNvvjiC06ePHnF7vbe0BBVRDzmyRA1Pj6e+Pj4Kt9/7LHH2L9/P0OGDOHOO+/klltu4dSpUxXv/9jd3huq4ETEY74cou7cuZMuXbqQmZlJ7969ad269RW723tDFZyIeMyXs6ht2rTh9ddfZ9myZTRq1Ijp06dTXFx8WXd7byjBiYjHfDmLGhkZyYoVKy7bv2rVqhofWwlORDymhb4iYllBkt+U4ETEc0aQpDglOBHxmNoGiohlBUl+U4ITEc9piHqVs498FUrOA2AWnMb16QfYHxkGZWWYx7/H9edMME0/Ryk/cpaVMWnGaxw9foJSp5MRT/wXf/rwI87k5wNw9PhJbrulE3NfSfVzpIFBs6hXs5B6AJQvnV6xyz7iFcr/lAmHv8XWeyBG556YX271V4TyL/7w/kaaNm7MrKkTKPjhBwYMG87/5KwF4IfCcwx5fhwTfzPCz1EGjmC5BapWEtyePXt4//33KSgo4Nprr6Vfv360bdu2Nk4VmK69AeqFYRuaAjYbrg+yoXEkHP4WAPP7vRiduijBBZB+9/+cvv+nV8Vru91e8XXG0t8zeOCjXNOiuT9CC0hBUsD5PhFv2LCBSZMmcd1113HfffcRERHB888/z8aNG319qsDlLMG19T1cK2bi+u/l2ONGQsEpaHsTAMZNd0JomJ+DlEtFhDegYUQ4jqJifjP5FZKfHgbA2YICPv3sc2J/9Us/RxhYbIbh9uZPPq/gVq5cyapVqwgPD6/YN2DAAEaMGEHv3r19fbrAdOYE5tmTF78+ewKKHZR/kI2t13/CfQ/B0QNQ5vRvjHKZ4ydPMWriSyTGPszDv3wAgL9szuWhX/6iUkUnV3EFFxISUim5ATRs2PCq+gtidPk5tv7/dfFFo6YQ1gAjqh2ud97ElfkaNGiIuf8rv8YolZ3JL+DJ0RMYP/IpBj7Uv2L/p9s/p1f3u/0YWWAyDMPtzZ98XsFV9QdyuVy+PlXAMv/2Pxixz2J/egqYUJ6zBCO8IfYh48FZgnlgN+beL/0dplxi0co1FJ47x8IVq1i44uJN3ktmp3Pw0GFaX3+dn6MLPO48BikQGKbp27UKPXv2pEePHpX2maZJXl4eW7dWf1G9LHWwL8ORWhaSnO7vEMQbLVrX6Nu/aN3W7c/efvi7Gp2rJnxewc2bN++K+wcNGuTrU4mIn3jR4MovfJ7gfmwUISLW5e9ra+7SQl8R8ViQ5DclOBHxnCo4EbEsX+Y3p9PJhAkTOHr0KDabjWnTphESEqLO9iLiH768Q2HLli2UlZWxbt06tm7dyrx583A6nepsLyL+YbMZbm/ViY6Opry8HJfLhcPhICQkxGed7VXBiYjHDA9Ko6ysrErd7P+1EXR4eDhHjx6lf//+FBQUsGjRIrZv367O9iLiH55MMlTX2X7FihXce++9jB07luPHj/PEE0/gdP50r7Y624tInTIM97fqNG7cmEaNGgHQpEkTysrK1NleRPzHl8tEhg4dyqRJk0hMTMTpdDJ69GhuvfVWdbYXEf/w5TKRiIgIXn/99cv2q7O9iPiFPUgeJ6IEJyIe050MImJZQZLflOBExHNKcCJiWYauwYmIVWmSQUQsS0NUEbEszaKKiGUFSX5TghMRz6mCExHLCpL8pgQnIp6z2YMjwynBiYjHNEQVEevSOjgRsSxVcCJiVRqiioh12YOj24ESnIh4TDfbi4h1+XCImpOTwzvvvANASUkJu3fvZs2aNcyYMaPGne2Do84UkYBi2Ay3t+rExsaSmZlJZmYmt9xyC6mpqfzud78jOTmZNWvWYJommzZt8irOKiu42bNnV3khccyYMV6dTEQsohYmGXbu3Mm+fftIS0tjwYIFlTrbb926lT59+nh8zCoTXExMjPeRioi1eXANrrrO9j9avHgxo0aNAsA0zdrtbD9gwAAAysrKeOeddzh+/DjdunWjQ4cOXp1IRKzD8GAWtbrO9gCFhYUcOHCA7t27A1S63larne3T0tI4duwYW7dupaioiJSUFK9OJCIW4svW9sD27dvp2bNnxWtfdbavNsEdOnSIF154gdDQUH7xi194XSqKiHUYNvc3dxw8eJCoqKiK1ykpKWRkZBAfH4/T6ay9zvbl5eXk5+djGAYOh8OrqVoRsRgfTzI89dRTlV5HR0fXTWf75ORkEhISOH36NPHx8UyaNKnGJxWR4GaZhb533303GzZsoKCggMjIyKC5B01EalGQ5IFqx5tbtmyhT58+PPXUU/Tr16/iwp+IXL0Mu83tzZ+qreAWLFjA+vXriYyM5PTp04waNYrs7Oy6iE1EApVVhqgRERFERkYC0LJlSxo0aFDrQYlIgAuSIWqVCW7OnDnAxVnUZ599li5durBjxw5CQ0PrLDgRCUzBci2+ygQXHR1d6f8ADzzwQO1HJCKBL9iHqJfeqrVz507KysowTZNTp07VWXAiEpj8PXngrmqvwT333HM4nU5OnTpFeXk511xzDQ899FBdxCYigSpIhqjVpmGHw8HSpUvp3LkzOTk5lJSU1EVcIhLAfPk8uNpUbQUXEnLxI+fPn6d+/fo4nc5aD0pEAlyQVHDVJrg+ffqwYMECbrrpJuLi4oiIiKiLuEQkkAXJJINhmqbp7oe/+eYb2rZtS1hYWO1FVPxD7R1bfG54RGt/hyBeWGQW1uj7y0Y+6PZnQxa+V6Nz1USVFdyYMWOqXOsye/bsWgtIRIJAsM+iDho0qC7jEJFgEuzX4H5s+CAicplgT3AiIlUKkgffKsGJiOesUsHt3buXl156iXPnzvHwww/ToUMH7r///rqITUQCVZAkuGrrzOnTp5Oenk7Tpk0ZOHAgGRkZdRGXiAQyu939zQ2LFy8mPj6e2NhY1q9fz/fff09CQgKJiYmkpaXhcrm8CtOtgXSbNm0wDIPIyEgt9BURn7YNzMvL4/PPP2ft2rVkZmZy4sQJ0tPTSU5OZs2aNZimyaZNm7wKs9ohapMmTVi3bh3nz5/nvffe87oBq4hYiAdD1Oo623/88cd07NiRUaNG4XA4ePHFF8nOzq5YydGrVy+2bt1Knz59PA6z2gQ3Y8YMFi1aRLNmzfjqq6+YPn26xycREYvxIMFV19m+oKCAY8eOsWjRIo4cOcKIESMwTbPiRoOIiAiv+zFXm+AKCwtJTEyseF1cXEzTpk29OpmIWIQPl4k0bdqUmJgYQkNDiYmJISwsjBMnTlS8X1RU5PXIsdoEN3r0aAzDwOVyceTIEdq0acPatWu9OpmIWIQPE1yXLl1YuXIlw4YN49SpU5w/f54ePXqQl5dHt27dyM3NpXv37l4du9oEd+nYubCwkKlTp3p1IhGxEB8uE7n//vvZvn07AwcOxDRNpk6dSlRUFFOmTGHOnDnExMTQt29fr47t0ULfRo0acejQIa9OJCLWYfj4ToYXX3zxsn2rVq2q8XGrTXDx8fEVF/vOnj1Lz549a3xSEQlyQbLQ161Z1Pr16wMQFhZGixYtaj0oEQlwQZLgqq0zU1NTadWqFa1atVJyE5GLfLjQtzZVW8GFh4czY8YMoqOjsf1z3P3v1rSIyFXAzVuw/K3aBHfHHXcAF6+/iYgAfq/M3FVtgrPZbIwcObLitR5XLiJBn+DWr1/PW2+9xf79+8nNzQXA5XLhdDoZO3ZsnQUoIgEo2B94+cgjj9CjRw8WL17M8OHDgYvVXPPmzessOBEJUMFewYWGhhIVFcW0adPqMh4RCQbBnuBERKpklVlUEZHLqIITEctSghMRywr2WVQRkSqpghMRy7JpkkFErMqmCk5ErMrQNTgRsSpdgxMRy/LxLOqjjz5Ko0aNAIiKimL48OFMmDABwzDo0KEDaWlpFY9r84QSnIh4zocVXElJCQCZmZkV+4YPH05ycjLdunVj6tSpbNq0qXYaP4uIXMaDWdTqOtvv2bOH8+fP8+STT1JWVsaYMWPYtWtX3XS2FxG5jAfDxeo629evX59f//rXPP7443z33Xc8/fTTddfZXkTkMj4cokZHR9OmTRsMwyA6OpqmTZuya9euivdr0tk+OOZ6RSSwGDb3t2q89dZb/Pa3vwXg5MmTOBwO7rnnHvLy8gDIzc2la9euXoWpCk5EPOfDhb4DBw5k4sSJJCQkYBgGM2bMoFmzZnXf2V5EBPDprVqhoaFX7PVSJ53tRUQuozsZRMSydC+qiFiWbtUSEcvSEFVELEtDVBGxLD3wUkQsS0NUEbEsDVFFxLJUwYmIZWmZyNXL6Sxj0svTOHrsGKWlTkY89STXX3ct02bOwm6zExpaj5nTXqJF8+b+DlWAtnd3JXbmy8y5/0FatovhiRVvYJomx776mnWjxmKaJnGv/1/a3dONknMOABY+ksCFwkI/R+5H6ot69frDnzfQtEkTZr36MgX/+AcDEpKIuv56pqSMp9ONHVn3Vg5Llq9k4rjR/g71qvfL8S/QLWkQJUXFAAycM4M/pE5j75aPSXxjLrc98iBfvPsnbrjzNub3HUDR2Xw/RxwggmQW1edpuKysjA8++IBt27ZV7Dtz5gzJycm+PlXA6tfnAV4Y+WzFa7vdzpzfTqfTjR0BKC8vJywszF/hySVO7z/I4tjBFa/bdLmdvVs+BmDXhg+5qff9GIbBNR3aMfjN+Yz/+AN6Dhtc1eGuHobh/uZHPq/gxo0bh91u5/Tp0+zbt4+oqCgmT57MkCFDfH2qgBURHg6Ao6iI34yfSPKo4VzTsgUAf/9iB6uy1rP6/y32Z4jyT5/n/IHmbW74accl/yAvnHPQoEljQiMi2JyxmI1zFmCz2xmz+U98/9nnHN256wpHvEpcrUPUQ4cOkZOTQ2lpKY899hj16tVj5cqVtGvXztenCmjHT5xk1JjxJMYN5OH+/QD48/sf8sbS5bw5fy6Rkc38HKFcielyVXxdv1FDzv/jB0qLi/no9Tdwnj8PwDcf5RJ1239c3QkuSCYZfJ6GGzZsCFx8xpPL5WLZsmVXXXI7c/YsT458nvEvPMfAR/8TgP9+bwOrsrLJXPIGraNa+TlCqcrhz3fQ8ef3AnBL/z58+7+f8LOO7Rn/8fsYNhu2kBDa3duDQ3//wr+B+psPn+hbm2p1kqF58+Y0bdq0Nk8RkBYtXUFhYSELlyxj4ZJllLvK+XbfAa6/7lqeH5sCwF1d7uQ3I57xc6Tyr94aO5nBS+YTEhrK8d3f8Pe33sV0ufjr6mxStn1EudPJtpVrOf71Hn+H6l9BMslgmKZp+vKAPXv2pEePHpimybZt2+jRo0fFe1d6audlin/wZThSy4ZHtPZ3COKFRWbNlriU52ZV/6F/svequqNWbfN5BTdv3ryKrwcNGuTrw4tIIPDx0PPs2bPExsaybNkyQkJCfNLVHmohwf3YrFVELMyHkwxOp5OpU6dSv359ANLT033S1R7UNlBEvOHDSYaZM2cyaNAgrrnmGoDLutp/8sknXoepBCciHjMMw+0tKyuL2NjYii0r66frdzk5OURGRnLfffdV7PNVV3vQrVoi4g2b+6kjPn4A8fFXnmh4++23MQyDTz/9lN27d5OSkkJ+/k+3w9Wkqz0owYmIN3z0PLjVq1dXfJ2UlMRLL73ErFmzyMvLo1u3buTm5tK9e3evj68hqoh4rhYX+qakpJCRkUF8fDxOp9PrrvZQC+vgakzr4IKK1sEFp5qug3N9tsHtz9q69q/RuWpCQ1QR8Zye6CsilhUkN9srwYmI5+zBcS+qEpyIeE5DVBGxLA1RRcSyVMGJiGWpghMRy7IHR+oIjihFJKAYquBExLJ0DU5ELEsVnIhYlio4EbEsVXAiYlm6VUtELEtDVBGxLA1RRcS6lOBExKpUwYmIZfkwwZWXl5OamsrBgwex2+2kp6djmqZPutsrwYmI53w4ybB582YA1q1bR15eXkWC80V3++CYChGRwGJ4sFWjd+/eTJs2DYBjx47RokULn3W3VwUnIl5wf4ialZVVqZt9fHz8ZY2gQ0JCSElJ4cMPP2T+/Pls3rzZJ93tleBExHMeXIO7UkK7kpkzZzJu3Dji4uIoKSmp2F+T7vYaooqI5wzD/a0a7777LosXLwagQYMGGIbBrbfeSl5eHgC5ubl07drVuzDV+FlqQo2fg1NNGz+bJw+4/VnjZzH/9v3i4mImTpzImTNnKCsr4+mnn6Zdu3ZMmTIFp9NJTEwMr776KnYvbg9TgpMaUYILTjVPcAfd/qzxs+ganasmdA1ORDynhb4iYllKcCJiXUpwImJRajojItal58GJiGWpghMRy1KCExHrUoITEatSBScilhUc+U0JTkS8oFlUEbEsDVFFxLqU4ETEqlTBiYhlKcGJiGUFySRD4D3wUkTER4IjDYuIeEEJTkQsSwlORCxLCU5ELEsJTkQsSwlORCxLCU5ELEsLfWtZXl4eycnJtG/fHtM0KSsrY8iQIfzqV7/yd2hyBZf+vgCKioqIioritddeIzQ01M/RiaeU4OpA9+7dmTt3LnDxH0xSUhLR0dF06tTJz5HJlVz6+wIYO3YsH330Ef369fNjVOINDVHrWEREBPHx8fzlL3/xdyjihtLSUk6dOkWTJk38HYp4QRWcHzRv3pxdu3b5OwypwrZt20hKSuLs2bPYbDbi4uLo0aOHv8MSL6iC84Njx45x7bXX+jsMqUL37t3JzMxk9erV1KtXj6ioKH+HJF5SgqtjDoeD9evX63pOEGjWrBmzZs0iNTWVU6dO+Tsc8YKGqHXgxyGPzWajvLyc559/npiYGH+HJW5o3749SUlJvPrqq8yfP9/f4YiH9LgkEbEsDVFFxLKU4ETEspTgRMSylOBExLKU4ETEspTgBIDRo0eTl5dHbm4uWVlZVX4uKysLp9Pp1jHXrl1LRkZGpX05OTm89tprVX5PRkYGa9eudev4nnxWrk5aByeV9OrV69++v3jxYh599NG6CUakhpTgglxOTg6bNm3C4XBQUFDAqFGj6Nu3Lw899BBt27YlNDSUl19+mcmTJ1NQUABAamoqN954I6tXr2b9+vW0bNmSs2fPVhzvwIEDjBs3joULF7Jx40bKy8tJSEjAbrdz+vRpRo8ezcKFC5k9ezbbt2/HNE2GDh1K//79+eyzz5gxYwZNmjTBZrNx++23Vxn77Nmz+eqrrygqKqJdu3akp6cDsHHjRjZs2MCFCxdITU2lc+fObNiwgRUrVmCz2ejSpQvjxo2r9Z+tBD8lOAsoLi5m+fLl5Ofn8/jjj/PAAw9QXFzMyJEjufnmm5k1axbdu3cnMTGR7777jokTJ/Lmm2+ycuVK/vjHP2IYBrGxsZWO+fXXX5Obm8v69espLS1l9uzZTJ48mTfeeIO5c+eyZcsWjhw5wrp16ygpKSEuLo577rmH9PR0Zs+eTXR0NGlpaVXG7HA4aNy4McuXL8flcvHggw9y8uRJAFq1asUrr7zCt99+y4svvsjy5cvJyMjg7bffpkGDBowfP56tW7fW6s9UrEEJzgLuuusubDYbLVq0oHHjxuTn5wMQHR0NwN69e9m2bRsbNmwAoLCwkAMHDtC+ffuKhzh27ty50jEPHjxI586dsdvtNGjQgNTU1Erv7927l127dpGUlARAWVkZx44d4+TJkxXnvfPOOzl06NAVYw4LCyM/P58xY8YQHh5OcXFxxbW9u+66C4AOHTpw+vRpDh06RH5+Ps888wxw8Zl6hw8frtkPTa4KmmSwgB8fvXTmzBkcDgfNmzcHwGa7+OuNiYlh6NChZGZmMm/ePB5++GFat27Nvn37uHDhAuXl5ezevbvSMWNiYvj6669xuVw4nU6GDRtGaWkphmHgcrmIiYmhW7duZGZm8vvf/57+/fsTFRVFy5Yt2b9/PwA7d+6sMubc3FyOHz/OnDlzGDNmDBcuXODHuwZ37NgBwDfffMP1119PVFQU1113HcuWLSMzM5PBgwdz2223+faHKJakCs4Czpw5wxNPPMG5c+dIS0vDbrdXen/48OFMnjyZ7OxsHA4Hzz33HJGRkbzwwgsMGjSIyMhIGjRoUOl7OnXqxH333UdCQgIul4uEhARCQ0Pp2rUrzzzzDCtXruSvf/0riYmJFBcX07t3bxo2bMisWbNISUkhIiKCiIiIKh8U2blzZxYuXEhcXByhoaG0bt264okdR44cYciQIZSWlvLKK68QGRnJ0KFDSUpKory8nFatWtG/f//a+WGKpehm+yB36aSAiFSmIaqIWJYqOBGxLFVwImJZSnAiYllKcCJiWUpwImJZSnAiYln/HxG+ckn82RccAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "labels = ['D','R']\n",
    "mat = confusion_matrix(y_test, pred, labels)\n",
    "sns.heatmap(mat, square=True, annot=True, fmt='d', cmap=\"Reds\",\n",
    "           xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel('predicted label')\n",
    "plt.ylabel('true label')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 839 entries, 0 to 511\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Aff         839 non-null    object\n",
      " 1   transcript  839 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 19.7+ KB\n"
     ]
    }
   ],
   "source": [
    "alldebates = pd.concat([allvpdebate, allpresdebate])\n",
    "alldebates.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D: red-states, problem-going, rudy-giuliani, net-zero, commander-chief, live-near, asking-people, learn-going, don-think, don-worry, going-going, 000-year, president-obama, know-joe, abraham-lincoln, make-china, need-help, people-country, god-going, business-china, know-know, 00-01, important-want, public-option, zero-emissions, 00-34, vice-president, future-bright, states-america, making-sure, 38-000, oil-industry, president-united, let-talk, make-sure, american-people, donald-trump, crosstalk-00, united-states, joe-biden\n",
      "None: pence-time, follow-vice, president-question, pence-senator, going-section, say-americans, minimum-wage, right-gentlemen, want-talk, ask-vice, lot-questions, good-evening, pence-thank, let-section, trump-reaction, okay-vice, biden-response, let-talk, mr-president, okay-let, let-vice, let-follow, final-question, biden-let, 10-seconds, north-korea, chance-respond, mr-vice, climate-change, right-let, crosstalk-00, minutes-uninterrupted, let-ask, thank-senator, senator-harris, president-biden, president-trump, thank-vice, president-pence, vice-president\n",
      "R: biden-vice, american-energy, young-people, american-jobs, look-happening, close-oil, kamala-harris, trump-tax, years-president, really-like, criminal-justice, trillion-dollars, ve-got, built-cages, cutting-taxes, russia-russia, don-come, left-mess, millions-dollars, socialized-medicine, small-businesses, abraham-lincoln, big-statement, years-ago, tax-cuts, supreme-court, history-country, green-new, new-deal, oil-industry, donald-trump, african-americans, vice-president, don-know, united-states, president-donald, crosstalk-00, president-trump, american-people, joe-biden\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(alldebates['transcript'], alldebates['Aff'], random_state=0,\n",
    "                                  train_size=0.6)\n",
    "nbmodel = MultinomialNB()\n",
    "vectorizer = TfidfVectorizer(ngram_range = (2,2), max_df=0.5, min_df=2,max_features=1500, stop_words='english') #using this to find vocab\n",
    "X_text_train = vectorizer.fit_transform(X_train)\n",
    "X_text_test = vectorizer.transform(X_test)\n",
    "\n",
    "\n",
    "nbmodel.fit(X_text_train, y_train)\n",
    "pred = nbmodel.predict(X_text_test)\n",
    "accuracy_score(y_test, pred) \n",
    "def print_top(vectorizer, clf, class_labels, n):\n",
    "    \"\"\"Prints features with the highest coefficient values, per class\"\"\"\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    for i, class_label in enumerate(class_labels):\n",
    "        top = np.argsort(clf.coef_[i])[0-n:]\n",
    "        print(\"%s: %s\" % (class_label,\n",
    "              \", \".join(feature_names[j].replace(' ', '-') for j in top)))\n",
    "    \n",
    "\n",
    "print_top(vectorizer, nbmodel, nbmodel.classes_, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                                       ('svc', SVC())]),\n",
       "             n_jobs=3,\n",
       "             param_grid={'svc__C': [1], 'svc__gamma': [1],\n",
       "                         'svc__kernel': ['linear'], 'tfidf__max_df': [0.5],\n",
       "                         'tfidf__max_features': [2000, 3000],\n",
       "                         'tfidf__stop_words': ['english', None]})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "x = alldebates.transcript[:1000] #making it smaller cause I'm scared of CRC\n",
    "y = alldebates.Aff[:1000]\n",
    "\n",
    "tfidf_model = TfidfVectorizer()\n",
    "svc_model = SVC()\n",
    "\n",
    "# create a pipeline with step names\n",
    "pipe = Pipeline(steps=[('tfidf', tfidf_model), ('svc', svc_model)])\n",
    "\n",
    "param_grid = {\n",
    "    'tfidf__max_features': [2000, 3000],        \n",
    "    'tfidf__stop_words': ['english', None],\n",
    "    'tfidf__max_df': [.5],\n",
    "    'svc__C': [1],\n",
    "    'svc__kernel' : ['linear'],\n",
    "    'svc__gamma' : [1]\n",
    "}                            # 8 parameter combos\n",
    "\n",
    "search = GridSearchCV(pipe, param_grid, n_jobs=3, cv=5)  # 8x5 = 40 models\n",
    "search.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'svc__C': 1, 'svc__gamma': 1, 'svc__kernel': 'linear', 'tfidf__max_df': 0.5, 'tfidf__max_features': 2000, 'tfidf__stop_words': None}\n",
      "best mean accuracy: 0.722291132021671\n"
     ]
    }
   ],
   "source": [
    "print('best parameters:', search.best_params_)     # best-performing parameter combo\n",
    "print('best mean accuracy:', search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D: come, plan, like, trying, got, didn, need, country, don, sure, trump, look, donald, jobs, true, 000, way, let, united, parents, make, saying, thank, america, money, american, biden, crosstalk, states, 00, china, fact, know, president, did, respond, people, going, joe, said\n",
      "None: korea, north, crosstalk, ve, sorry, final, need, chance, 00, 10, questions, said, issue, uninterrupted, yes, mr, time, talk, want, minutes, seconds, section, ask, follow, respond, quickly, response, going, question, senator, harris, biden, right, trump, okay, let, pence, thank, vice, president\n",
      "R: tax, crosstalk, work, statement, biggest, country, big, fracking, kristen, want, like, china, come, thing, 00, deal, don, biden, senator, susan, think, got, ll, russia, look, know, say, didn, years, did, said, just, going, ve, trump, people, president, joe, american, excuse\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(alldebates['transcript'], alldebates['Aff'], random_state=0,\n",
    "                                  train_size=0.6)\n",
    "nbmodel = MultinomialNB()\n",
    "vectorizer = TfidfVectorizer(max_df=0.5, min_df=2,max_features=1500, stop_words='english') #using this to find vocab\n",
    "X_text_train = vectorizer.fit_transform(X_train)\n",
    "X_text_test = vectorizer.transform(X_test)\n",
    "\n",
    "\n",
    "nbmodel.fit(X_text_train, y_train)\n",
    "pred = nbmodel.predict(X_text_test)\n",
    "accuracy_score(y_test, pred) \n",
    "def print_top(vectorizer, clf, class_labels, n):\n",
    "    \"\"\"Prints features with the highest coefficient values, per class\"\"\"\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    for i, class_label in enumerate(class_labels):\n",
    "        top = np.argsort(clf.coef_[i])[0-n:]\n",
    "        print(\"%s: %s\" % (class_label,\n",
    "              \", \".join(feature_names[j].replace(' ', '-') for j in top)))\n",
    "    \n",
    "\n",
    "print_top(vectorizer, nbmodel, nbmodel.classes_, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
